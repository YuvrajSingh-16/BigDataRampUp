[+] Generating data
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.lib.MutableMetricsFactory).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
[+] 1000000 Rows Data Generation Done!!!


[+] Checking Older Archives...
list index out of range


[+] Adding new JSON to the Archives...
cp: `/user/hadoopusr/clickstream/archive_data//01-12-2022': No such file or directory


[+] Calling MR Job for LocationWise Analysis
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.lib.MutableMetricsFactory).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
[+] mapreduce.framework set to local
[+] All configurations are set !!!
Dec 01, 2022 4:00:10 PM com.uvsingh.mr.MyMapper <init>
INFO: [+] Mapper Object Created.
Dec 01, 2022 4:00:14 PM com.uvsingh.mr.MyCombiner <init>
INFO: [+] MyCombiner object created.
Dec 01, 2022 4:00:14 PM com.uvsingh.mr.MyMapper <init>
INFO: [+] Mapper Object Created.
Dec 01, 2022 4:00:17 PM com.uvsingh.mr.MyCombiner <init>
INFO: [+] MyCombiner object created.
Dec 01, 2022 4:00:18 PM com.uvsingh.mr.MyMapper <init>
INFO: [+] Mapper Object Created.
Dec 01, 2022 4:00:20 PM com.uvsingh.mr.MyCombiner <init>
INFO: [+] MyCombiner object created.
Dec 01, 2022 4:00:20 PM com.uvsingh.mr.MyMapper <init>
INFO: [+] Mapper Object Created.
Dec 01, 2022 4:00:23 PM com.uvsingh.mr.MyCombiner <init>
INFO: [+] MyCombiner object created.
Dec 01, 2022 4:00:23 PM com.uvsingh.mr.MyReducer <init>
INFO: [+] MyReducer Object Created.
Dec 01, 2022 4:00:24 PM com.uvsingh.mr.MyDriver main
INFO: MAP-REDUCE ANALYSIS JOB COMPLETED


[+] Creating Clickstream_db & clickstream table

Logging initialized using configuration in jar:file:/usr/local/hive/lib/hive-common-2.3.9.jar!/hive-log4j2.properties Async: true
OK
Time taken: 6.166 seconds
OK
Time taken: 0.29 seconds
OK
Time taken: 0.06 seconds
OK
Time taken: 0.194 seconds
Loading data to table clickstream_db.clickstream_tmp
OK
Time taken: 0.467 seconds
OK
Time taken: 0.17 seconds
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = hadoopusr_20221201160037_7bc117a2-2eff-4986-9b0b-353aca1c87d0
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks determined at compile time: 4
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1669878452049_0017, Tracking URL = http://uvsingh-workstation:8088/proxy/application_1669878452049_0017/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1669878452049_0017
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 4
2022-12-01 16:00:43,484 Stage-1 map = 0%,  reduce = 0%
2022-12-01 16:00:51,888 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 5.26 sec
2022-12-01 16:00:59,110 Stage-1 map = 85%,  reduce = 0%, Cumulative CPU 18.58 sec
2022-12-01 16:01:02,279 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 20.22 sec
2022-12-01 16:01:05,495 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 22.04 sec
2022-12-01 16:01:09,664 Stage-1 map = 100%,  reduce = 42%, Cumulative CPU 27.63 sec
2022-12-01 16:01:12,802 Stage-1 map = 100%,  reduce = 58%, Cumulative CPU 35.68 sec
2022-12-01 16:01:13,821 Stage-1 map = 100%,  reduce = 83%, Cumulative CPU 44.43 sec
2022-12-01 16:01:15,901 Stage-1 map = 100%,  reduce = 92%, Cumulative CPU 48.14 sec
2022-12-01 16:01:17,948 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 54.39 sec
MapReduce Total cumulative CPU time: 54 seconds 390 msec
Ended Job = job_1669878452049_0017
Loading data to table clickstream_db.clickstream partition (location=null)


	 Time taken to load dynamic partitions: 2.162 seconds
	 Time taken for adding to write entity : 0.003 seconds
Launching Job 2 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1669878452049_0018, Tracking URL = http://uvsingh-workstation:8088/proxy/application_1669878452049_0018/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1669878452049_0018
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2022-12-01 16:01:29,028 Stage-3 map = 0%,  reduce = 0%
2022-12-01 16:01:33,137 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 0.94 sec
2022-12-01 16:01:38,253 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 2.27 sec
MapReduce Total cumulative CPU time: 2 seconds 270 msec
Ended Job = job_1669878452049_0018
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 4   Cumulative CPU: 54.39 sec   HDFS Read: 481654541 HDFS Write: 441413051 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 2.27 sec   HDFS Read: 278880 HDFS Write: 102534 SUCCESS
Total MapReduce CPU Time Spent: 56 seconds 660 msec
OK
Time taken: 65.113 seconds


[+] Inserting MR output into Hive table

Logging initialized using configuration in jar:file:/usr/local/hive/lib/hive-common-2.3.9.jar!/hive-log4j2.properties Async: true
OK
Time taken: 4.118 seconds


[+] Calling HIVE Job MostActiveUsers.hql

Logging initialized using configuration in jar:file:/usr/local/hive/lib/hive-common-2.3.9.jar!/hive-log4j2.properties Async: true
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = hadoopusr_20221201160155_5cf3aee2-f92b-4de4-96a6-59e3bccf157a
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1669878452049_0019, Tracking URL = http://uvsingh-workstation:8088/proxy/application_1669878452049_0019/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1669878452049_0019
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2022-12-01 16:02:07,123 Stage-1 map = 0%,  reduce = 0%
2022-12-01 16:02:16,527 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 6.16 sec
2022-12-01 16:02:18,593 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 13.8 sec
2022-12-01 16:02:21,737 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 15.04 sec
2022-12-01 16:02:23,851 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 16.93 sec
MapReduce Total cumulative CPU time: 16 seconds 930 msec
Ended Job = job_1669878452049_0019
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1669878452049_0020, Tracking URL = http://uvsingh-workstation:8088/proxy/application_1669878452049_0020/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1669878452049_0020
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2022-12-01 16:02:34,662 Stage-2 map = 0%,  reduce = 0%
2022-12-01 16:02:38,790 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.35 sec
2022-12-01 16:02:44,947 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 3.1 sec
MapReduce Total cumulative CPU time: 3 seconds 100 msec
Ended Job = job_1669878452049_0020
Moving data to directory hdfs://localhost:9000/user/hive/warehouse/clickstream_db.db/activeusers
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 16.93 sec   HDFS Read: 441198115 HDFS Write: 861 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 3.1 sec   HDFS Read: 7626 HDFS Write: 462 SUCCESS
Total MapReduce CPU Time Spent: 20 seconds 30 msec
OK
Time taken: 51.429 seconds


[+] Calling HIVE Job UserItemVisitAnalysis.hql

Logging initialized using configuration in jar:file:/usr/local/hive/lib/hive-common-2.3.9.jar!/hive-log4j2.properties Async: true
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Query ID = hadoopusr_20221201160251_052675f3-9932-43b8-a767-bb9fc8bc9a73
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1669878452049_0021, Tracking URL = http://uvsingh-workstation:8088/proxy/application_1669878452049_0021/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1669878452049_0021
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 2
2022-12-01 16:03:02,992 Stage-1 map = 0%,  reduce = 0%
2022-12-01 16:03:14,496 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 8.5 sec
2022-12-01 16:03:15,524 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 17.26 sec
2022-12-01 16:03:20,714 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 19.74 sec
2022-12-01 16:03:21,745 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 21.77 sec
MapReduce Total cumulative CPU time: 21 seconds 770 msec
Ended Job = job_1669878452049_0021
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1669878452049_0022, Tracking URL = http://uvsingh-workstation:8088/proxy/application_1669878452049_0022/
Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1669878452049_0022
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2022-12-01 16:03:32,334 Stage-2 map = 0%,  reduce = 0%
2022-12-01 16:03:37,518 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.64 sec
2022-12-01 16:03:41,611 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.98 sec
MapReduce Total cumulative CPU time: 2 seconds 980 msec
Ended Job = job_1669878452049_0022
Moving data to directory hdfs://localhost:9000/user/hive/warehouse/clickstream_db.db/useritemvisit
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 2   Cumulative CPU: 21.77 sec   HDFS Read: 441199473 HDFS Write: 848 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 2.98 sec   HDFS Read: 7487 HDFS Write: 405 SUCCESS
Total MapReduce CPU Time Spent: 24 seconds 750 msec
OK
Time taken: 51.949 seconds


[+] Calling Spark Job DayWiseTrafficAnalysis.py
22/12/01 16:03:45 WARN Utils: Your hostname, uvsingh-workstation resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)
22/12/01 16:03:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
22/12/01 16:03:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[Stage 0:>                                                        (0 + 3) / 124][Stage 0:=======>                                                (17 + 3) / 124][Stage 0:================>                                       (36 + 3) / 124][Stage 0:===========================>                            (61 + 4) / 124][Stage 0:====================================>                   (81 + 4) / 124][Stage 0:==============================================>        (104 + 3) / 124]                                                                                [Stage 1:>                                                          (0 + 3) / 7][Stage 1:========>                                                  (1 + 3) / 7][Stage 1:================>                                          (2 + 3) / 7][Stage 1:=========================>                                 (3 + 3) / 7][Stage 1:=================================>                         (4 + 3) / 7][Stage 1:==========================================>                (5 + 2) / 7]                                                                                2022-12-01T16:03:59,571 INFO [Thread-3] org.apache.hadoop.hive.conf.HiveConf - Found configuration file file:/usr/local/hive/conf/hive-site.xml
2022-12-01T16:04:00,067 WARN [Thread-3] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.jdbc.timeout does not exist
2022-12-01T16:04:00,067 WARN [Thread-3] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.retries.wait does not exist
2022-12-01T16:04:00,068 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2022-12-01T16:04:00,107 INFO [Thread-3] org.apache.hadoop.hive.metastore.ObjectStore - ObjectStore, initialize called
2022-12-01T16:04:00,238 INFO [Thread-3] DataNucleus.Persistence - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2022-12-01T16:04:00,238 INFO [Thread-3] DataNucleus.Persistence - Property datanucleus.cache.level2 unknown - will be ignored
2022-12-01T16:04:00,517 INFO [Thread-3] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Started.
2022-12-01T16:04:01,007 INFO [Thread-3] com.zaxxer.hikari.HikariDataSource - HikariPool-2 - Started.
2022-12-01T16:04:01,306 INFO [Thread-3] org.apache.hadoop.hive.metastore.ObjectStore - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2022-12-01T16:04:02,277 INFO [Thread-3] org.apache.hadoop.hive.metastore.MetaStoreDirectSql - Using direct SQL, underlying DB is MYSQL
2022-12-01T16:04:02,279 INFO [Thread-3] org.apache.hadoop.hive.metastore.ObjectStore - Initialized ObjectStore
2022-12-01T16:04:02,393 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - Added admin role in metastore
2022-12-01T16:04:02,396 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - Added public role in metastore
2022-12-01T16:04:02,412 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - No user is added in admin role, since config is empty
2022-12-01T16:04:02,480 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: default
2022-12-01T16:04:02,482 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: default	
2022-12-01T16:04:02,489 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: global_temp
2022-12-01T16:04:02,490 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: global_temp	
2022-12-01T16:04:02,493 WARN [Thread-3] org.apache.hadoop.hive.metastore.ObjectStore - Failed to get database global_temp, returning NoSuchObjectException
2022-12-01T16:04:02,495 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: clickstream_db
2022-12-01T16:04:02,495 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: clickstream_db	
2022-12-01T16:04:02,879 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_table : db=clickstream_db tbl=daywise_traffic_analysis
2022-12-01T16:04:02,880 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_table : db=clickstream_db tbl=daywise_traffic_analysis	
2022-12-01T16:04:02,890 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: clickstream_db
2022-12-01T16:04:02,890 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: clickstream_db	
2022-12-01T16:04:02,897 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: clickstream_db
2022-12-01T16:04:02,897 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: clickstream_db	
2022-12-01T16:04:02,906 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: clickstream_db
2022-12-01T16:04:02,906 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: clickstream_db	
2022-12-01T16:04:02,911 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: clickstream_db
2022-12-01T16:04:02,911 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: clickstream_db	
[Stage 3:>                                                          (0 + 3) / 7][Stage 3:=========================>                                 (3 + 3) / 7][Stage 3:==================================================>        (6 + 1) / 7]                                                                                [Stage 10:>                                                         (0 + 1) / 1]                                                                                2022-12-01T16:04:08,094 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: clickstream_db
2022-12-01T16:04:08,095 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: clickstream_db	
2022-12-01T16:04:08,107 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_table : db=clickstream_db tbl=daywise_traffic_analysis
2022-12-01T16:04:08,107 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_table : db=clickstream_db tbl=daywise_traffic_analysis	
2022-12-01T16:04:08,116 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: clickstream_db
2022-12-01T16:04:08,116 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: clickstream_db	
2022-12-01T16:04:08,129 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_table : db=clickstream_db tbl=daywise_traffic_analysis
2022-12-01T16:04:08,129 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_table : db=clickstream_db tbl=daywise_traffic_analysis	
2022-12-01T16:04:08,211 INFO [Thread-3] org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAccessController - Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=ee2a0f46-2326-4b8e-831e-f882a30a36bd, clientType=HIVECLI]
2022-12-01T16:04:08,216 WARN [Thread-3] org.apache.hadoop.hive.ql.session.SessionState - METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
2022-12-01T16:04:08,217 INFO [Thread-3] hive.metastore - Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
2022-12-01T16:04:08,219 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: Cleaning up thread local RawStore...
2022-12-01T16:04:08,220 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2022-12-01T16:04:08,220 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: Done cleaning up thread local RawStore
2022-12-01T16:04:08,220 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2022-12-01T16:04:08,338 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: create_table: Table(tableName:daywise_traffic_analysis, dbName:clickstream_db, owner:hadoopusr, createTime:1669890842, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:day_of_week, type:string, comment:null), FieldSchema(name:traffic_count, type:bigint, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{path=hdfs://localhost:9000/user/hive/warehouse/clickstream_db.db/daywise_traffic_analysis, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{spark.sql.sources.schema={"type":"struct","fields":[{"name":"day_of_week","type":"string","nullable":true,"metadata":{}},{"name":"traffic_count","type":"long","nullable":true,"metadata":{}}]}, spark.sql.sources.provider=parquet, spark.sql.create.version=3.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{hadoopusr=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:hadoopusr, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:hadoopusr, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:hadoopusr, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:hadoopusr, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null))
2022-12-01T16:04:08,338 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=create_table: Table(tableName:daywise_traffic_analysis, dbName:clickstream_db, owner:hadoopusr, createTime:1669890842, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:day_of_week, type:string, comment:null), FieldSchema(name:traffic_count, type:bigint, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{path=hdfs://localhost:9000/user/hive/warehouse/clickstream_db.db/daywise_traffic_analysis, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{spark.sql.sources.schema={"type":"struct","fields":[{"name":"day_of_week","type":"string","nullable":true,"metadata":{}},{"name":"traffic_count","type":"long","nullable":true,"metadata":{}}]}, spark.sql.sources.provider=parquet, spark.sql.create.version=3.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{hadoopusr=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:hadoopusr, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:hadoopusr, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:hadoopusr, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:hadoopusr, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null))	
2022-12-01T16:04:08,381 WARN [Thread-3] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2022-12-01T16:04:08,381 WARN [Thread-3] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.jdbc.timeout does not exist
2022-12-01T16:04:08,382 WARN [Thread-3] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.retries.wait does not exist
2022-12-01T16:04:08,382 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2022-12-01T16:04:08,383 INFO [Thread-3] org.apache.hadoop.hive.metastore.ObjectStore - ObjectStore, initialize called
2022-12-01T16:04:08,396 INFO [Thread-3] org.apache.hadoop.hive.metastore.MetaStoreDirectSql - Using direct SQL, underlying DB is MYSQL
2022-12-01T16:04:08,396 INFO [Thread-3] org.apache.hadoop.hive.metastore.ObjectStore - Initialized ObjectStore
2022-12-01T16:04:08,416 INFO [Thread-3] hive.log - Updating table stats fast for daywise_traffic_analysis
2022-12-01T16:04:08,417 INFO [Thread-3] hive.log - Updated size of table daywise_traffic_analysis to 821
[+] Loading data into Dataframe...
+--------+----------+--------------------+--------------+--------------------+--------------------+------------------+--------+
|  action|   logdate|             logtime|payment_method|           sessionid|                 url|            userid|location|
+--------+----------+--------------------+--------------+--------------------+--------------------+------------------+--------+
|    view|2022-09-22|2022-09-22 09:58:...|            NA|Session_clickShop...|http://www.shop.c...|      Matt Murdock|  Ujjain|
|purchase|2022-08-27|2022-08-27 12:42:...|    NetBanking|Session_clickShop...|http://www.shop.c...|       Chris Evans|  Ujjain|
|purchase|2022-08-13|2022-08-13 04:09:...|   Credit Card|Session_clickShop...|http://www.shop.c...|     Jessica Jones|  Ujjain|
|purchase|2022-11-12|2022-11-12 07:03:...|           UPI|Session_clickShop...|http://www.shop.c...|      Matt Murdock|  Ujjain|
|    view|2022-09-07|2022-09-07 10:30:...|            NA|Session_clickShop...|http://www.shop.c...|     Claire Temple|  Ujjain|
|    view|2022-09-10|2022-09-10 09:21:...|            NA|Session_clickShop...|http://www.shop.c...|      Foggy Nelson|  Ujjain|
|    view|2022-06-26|2022-06-26 01:44:...|            NA|Session_clickShop...|http://www.shop.c...|        Karen Page|  Ujjain|
|purchase|2022-11-06|2022-11-06 06:51:...|           COD|Session_clickShop...|http://www.shop.c...|           Lucifer|  Ujjain|
|    view|2022-10-26|2022-10-26 02:19:...|            NA|Session_clickShop...|http://www.shop.c...|     Ryan Reynolds|  Ujjain|
|purchase|2022-07-12|2022-07-12 07:11:...|   Credit Card|Session_clickShop...|http://www.shop.c...|      Peter Parker|  Ujjain|
|    view|2022-10-06|2022-10-06 12:29:...|            NA|Session_clickShop...|http://www.shop.c...|        Tony Stark|  Ujjain|
|purchase|2022-06-27|2022-06-27 11:37:...|        PayPal|Session_clickShop...|http://www.shop.c...|     Ryan Reynolds|  Ujjain|
|purchase|2022-07-26|2022-07-26 05:51:...|    Debit Card|Session_clickShop...|http://www.shop.c...|     Ryan Reynolds|  Ujjain|
|purchase|2022-08-03|2022-08-03 12:01:...|    NetBanking|Session_clickShop...|http://www.shop.c...|     Jessica Jones|  Ujjain|
|purchase|2022-09-15|2022-09-15 05:56:...|        PayPal|Session_clickShop...|http://www.shop.c...|      Clint Barton|  Ujjain|
|purchase|2022-07-06|2022-07-06 01:46:...|   Credit Card|Session_clickShop...|http://www.shop.c...|        Tony Stark|  Ujjain|
|    view|2022-06-16|2022-06-16 09:16:...|            NA|Session_clickShop...|http://www.shop.c...|Scarlett Johansson|  Ujjain|
|purchase|2022-11-06|2022-11-06 11:51:...|   Credit Card|Session_clickShop...|http://www.shop.c...|     Claire Temple|  Ujjain|
|purchase|2022-10-20|2022-10-20 11:46:...|    Debit Card|Session_clickShop...|http://www.shop.c...|       Chris Evans|  Ujjain|
|purchase|2022-10-23|2022-10-23 10:55:...|        PayPal|Session_clickShop...|http://www.shop.c...|           Elektra|  Ujjain|
+--------+----------+--------------------+--------------+--------------------+--------------------+------------------+--------+
only showing top 20 rows

root
 |-- action: string (nullable = true)
 |-- logdate: string (nullable = true)
 |-- logtime: string (nullable = true)
 |-- payment_method: string (nullable = true)
 |-- sessionid: string (nullable = true)
 |-- url: string (nullable = true)
 |-- userid: string (nullable = true)
 |-- location: string (nullable = true)

[+] Day Wise Traffic Analysis data stores in hive table successfully...!!!


[+] Calling Spark Job ShoppingCartAnalysis_item.py
22/12/01 16:04:10 WARN Utils: Your hostname, uvsingh-workstation resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)
22/12/01 16:04:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
22/12/01 16:04:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[Stage 0:>                                                        (0 + 3) / 124][Stage 0:>                                                        (1 + 3) / 124][Stage 0:============>                                           (27 + 3) / 124][Stage 0:=======================>                                (51 + 3) / 124][Stage 0:====================================>                   (81 + 3) / 124][Stage 0:==================================================>    (114 + 3) / 124]                                                                                [Stage 1:>                                                          (0 + 3) / 7][Stage 1:========>                                                  (1 + 3) / 7][Stage 1:=========================>                                 (3 + 3) / 7][Stage 1:=================================>                         (4 + 3) / 7][Stage 1:==================================================>        (6 + 1) / 7]                                                                                2022-12-01T16:04:22,593 INFO [Thread-3] org.apache.hadoop.hive.conf.HiveConf - Found configuration file file:/usr/local/hive/conf/hive-site.xml
2022-12-01T16:04:22,968 WARN [Thread-3] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.jdbc.timeout does not exist
2022-12-01T16:04:22,968 WARN [Thread-3] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.retries.wait does not exist
2022-12-01T16:04:22,968 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2022-12-01T16:04:22,998 INFO [Thread-3] org.apache.hadoop.hive.metastore.ObjectStore - ObjectStore, initialize called
2022-12-01T16:04:23,099 INFO [Thread-3] DataNucleus.Persistence - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2022-12-01T16:04:23,099 INFO [Thread-3] DataNucleus.Persistence - Property datanucleus.cache.level2 unknown - will be ignored
2022-12-01T16:04:23,289 INFO [Thread-3] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Started.
2022-12-01T16:04:23,670 INFO [Thread-3] com.zaxxer.hikari.HikariDataSource - HikariPool-2 - Started.
2022-12-01T16:04:24,004 INFO [Thread-3] org.apache.hadoop.hive.metastore.ObjectStore - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2022-12-01T16:04:24,938 INFO [Thread-3] org.apache.hadoop.hive.metastore.MetaStoreDirectSql - Using direct SQL, underlying DB is MYSQL
2022-12-01T16:04:24,940 INFO [Thread-3] org.apache.hadoop.hive.metastore.ObjectStore - Initialized ObjectStore
2022-12-01T16:04:25,043 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - Added admin role in metastore
2022-12-01T16:04:25,046 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - Added public role in metastore
2022-12-01T16:04:25,063 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - No user is added in admin role, since config is empty
2022-12-01T16:04:25,130 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: default
2022-12-01T16:04:25,132 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: default	
2022-12-01T16:04:25,139 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: global_temp
2022-12-01T16:04:25,139 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: global_temp	
2022-12-01T16:04:25,142 WARN [Thread-3] org.apache.hadoop.hive.metastore.ObjectStore - Failed to get database global_temp, returning NoSuchObjectException
2022-12-01T16:04:25,145 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: clickstream_db
2022-12-01T16:04:25,145 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: clickstream_db	
2022-12-01T16:04:25,914 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_table : db=clickstream_db tbl=shopping_cart_analysis
2022-12-01T16:04:25,914 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_table : db=clickstream_db tbl=shopping_cart_analysis	
2022-12-01T16:04:25,924 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: clickstream_db
2022-12-01T16:04:25,925 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: clickstream_db	
2022-12-01T16:04:25,932 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: clickstream_db
2022-12-01T16:04:25,932 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: clickstream_db	
2022-12-01T16:04:25,940 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: clickstream_db
2022-12-01T16:04:25,941 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: clickstream_db	
2022-12-01T16:04:25,945 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: clickstream_db
2022-12-01T16:04:25,946 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: clickstream_db	
[Stage 3:>                                                          (0 + 3) / 7][Stage 3:>                  (0 + 3) / 7][Stage 4:>                  (0 + 0) / 7][Stage 3:>    (0 + 3) / 7][Stage 4:>    (0 + 0) / 7][Stage 5:>    (0 + 0) / 7][Stage 3:==>  (3 + 3) / 7][Stage 4:>    (0 + 0) / 7][Stage 5:>    (0 + 0) / 7][Stage 3:==>  (4 + 3) / 7][Stage 4:>    (0 + 0) / 7][Stage 5:>    (0 + 0) / 7][Stage 4:>    (0 + 3) / 7][Stage 5:>    (0 + 0) / 7][Stage 6:>    (0 + 0) / 7][Stage 4:>    (1 + 3) / 7][Stage 5:>    (0 + 0) / 7][Stage 6:>    (0 + 0) / 7][Stage 4:==>  (3 + 3) / 7][Stage 5:>    (0 + 0) / 7][Stage 6:>    (0 + 0) / 7][Stage 4:==>  (4 + 3) / 7][Stage 5:>    (0 + 0) / 7][Stage 6:>    (0 + 0) / 7][Stage 4:====>(6 + 1) / 7][Stage 5:>    (0 + 2) / 7][Stage 6:>    (0 + 0) / 7][Stage 5:>    (0 + 3) / 7][Stage 6:>    (0 + 0) / 7][Stage 8:>    (0 + 0) / 1][Stage 5:>    (1 + 3) / 7][Stage 6:>    (0 + 0) / 7][Stage 8:>    (0 + 0) / 1][Stage 5:=>   (2 + 3) / 7][Stage 6:>    (0 + 0) / 7][Stage 8:>    (0 + 0) / 1][Stage 5:==>  (3 + 3) / 7][Stage 6:>    (0 + 0) / 7][Stage 8:>    (0 + 0) / 1][Stage 5:==>  (4 + 3) / 7][Stage 6:>    (0 + 0) / 7][Stage 8:>    (0 + 0) / 1][Stage 5:====>(6 + 1) / 7][Stage 6:>    (0 + 2) / 7][Stage 8:>    (0 + 0) / 1][Stage 6:>    (0 + 3) / 7][Stage 8:>    (0 + 0) / 1][Stage 10:>   (0 + 0) / 1][Stage 6:=>   (2 + 3) / 7][Stage 8:>    (0 + 0) / 1][Stage 10:>   (0 + 0) / 1][Stage 6:==>  (3 + 3) / 7][Stage 8:>    (0 + 0) / 1][Stage 10:>   (0 + 0) / 1][Stage 6:====>(6 + 1) / 7][Stage 8:>    (0 + 1) / 1][Stage 10:>   (0 + 1) / 1]                                                                                [Stage 17:>                                                         (0 + 1) / 1]                                                                                2022-12-01T16:04:35,656 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: clickstream_db
2022-12-01T16:04:35,656 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: clickstream_db	
2022-12-01T16:04:35,665 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_table : db=clickstream_db tbl=shopping_cart_analysis
2022-12-01T16:04:35,666 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_table : db=clickstream_db tbl=shopping_cart_analysis	
2022-12-01T16:04:35,673 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: clickstream_db
2022-12-01T16:04:35,673 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_database: clickstream_db	
2022-12-01T16:04:35,681 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_table : db=clickstream_db tbl=shopping_cart_analysis
2022-12-01T16:04:35,681 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=get_table : db=clickstream_db tbl=shopping_cart_analysis	
2022-12-01T16:04:35,735 INFO [Thread-3] org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAccessController - Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=6e023e24-a77c-49ed-877b-197143ead898, clientType=HIVECLI]
2022-12-01T16:04:35,737 WARN [Thread-3] org.apache.hadoop.hive.ql.session.SessionState - METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
2022-12-01T16:04:35,737 INFO [Thread-3] hive.metastore - Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
2022-12-01T16:04:35,739 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: Cleaning up thread local RawStore...
2022-12-01T16:04:35,739 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2022-12-01T16:04:35,741 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: Done cleaning up thread local RawStore
2022-12-01T16:04:35,741 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2022-12-01T16:04:35,819 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: create_table: Table(tableName:shopping_cart_analysis, dbName:clickstream_db, owner:hadoopusr, createTime:1669890865, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:item, type:string, comment:null), FieldSchema(name:view_count, type:bigint, comment:null), FieldSchema(name:addtocart_count, type:bigint, comment:null), FieldSchema(name:removefromcart_count, type:bigint, comment:null), FieldSchema(name:purchase_count, type:bigint, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{path=hdfs://localhost:9000/user/hive/warehouse/clickstream_db.db/shopping_cart_analysis, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{spark.sql.sources.schema={"type":"struct","fields":[{"name":"item","type":"string","nullable":true,"metadata":{}},{"name":"view_count","type":"long","nullable":true,"metadata":{}},{"name":"addtocart_count","type":"long","nullable":true,"metadata":{}},{"name":"removefromcart_count","type":"long","nullable":true,"metadata":{}},{"name":"purchase_count","type":"long","nullable":true,"metadata":{}}]}, spark.sql.sources.provider=parquet, spark.sql.create.version=3.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{hadoopusr=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:hadoopusr, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:hadoopusr, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:hadoopusr, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:hadoopusr, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null))
2022-12-01T16:04:35,819 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=hadoopusr	ip=unknown-ip-addr	cmd=create_table: Table(tableName:shopping_cart_analysis, dbName:clickstream_db, owner:hadoopusr, createTime:1669890865, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:item, type:string, comment:null), FieldSchema(name:view_count, type:bigint, comment:null), FieldSchema(name:addtocart_count, type:bigint, comment:null), FieldSchema(name:removefromcart_count, type:bigint, comment:null), FieldSchema(name:purchase_count, type:bigint, comment:null)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{path=hdfs://localhost:9000/user/hive/warehouse/clickstream_db.db/shopping_cart_analysis, serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{spark.sql.sources.schema={"type":"struct","fields":[{"name":"item","type":"string","nullable":true,"metadata":{}},{"name":"view_count","type":"long","nullable":true,"metadata":{}},{"name":"addtocart_count","type":"long","nullable":true,"metadata":{}},{"name":"removefromcart_count","type":"long","nullable":true,"metadata":{}},{"name":"purchase_count","type":"long","nullable":true,"metadata":{}}]}, spark.sql.sources.provider=parquet, spark.sql.create.version=3.3.0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{hadoopusr=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:hadoopusr, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:hadoopusr, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:hadoopusr, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:hadoopusr, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null))	
2022-12-01T16:04:35,849 WARN [Thread-3] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
2022-12-01T16:04:35,849 WARN [Thread-3] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.jdbc.timeout does not exist
2022-12-01T16:04:35,849 WARN [Thread-3] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.retries.wait does not exist
2022-12-01T16:04:35,849 INFO [Thread-3] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2022-12-01T16:04:35,850 INFO [Thread-3] org.apache.hadoop.hive.metastore.ObjectStore - ObjectStore, initialize called
2022-12-01T16:04:35,862 INFO [Thread-3] org.apache.hadoop.hive.metastore.MetaStoreDirectSql - Using direct SQL, underlying DB is MYSQL
2022-12-01T16:04:35,862 INFO [Thread-3] org.apache.hadoop.hive.metastore.ObjectStore - Initialized ObjectStore
2022-12-01T16:04:35,877 INFO [Thread-3] hive.log - Updating table stats fast for shopping_cart_analysis
2022-12-01T16:04:35,877 INFO [Thread-3] hive.log - Updated size of table shopping_cart_analysis to 2213
[+] Loading data into dataframe..
+--------+----------+--------------------+--------------+--------------------+--------------------+------------------+--------+
|  action|   logdate|             logtime|payment_method|           sessionid|                 url|            userid|location|
+--------+----------+--------------------+--------------+--------------------+--------------------+------------------+--------+
|    view|2022-09-22|2022-09-22 09:58:...|            NA|Session_clickShop...|http://www.shop.c...|      Matt Murdock|  Ujjain|
|purchase|2022-08-27|2022-08-27 12:42:...|    NetBanking|Session_clickShop...|http://www.shop.c...|       Chris Evans|  Ujjain|
|purchase|2022-08-13|2022-08-13 04:09:...|   Credit Card|Session_clickShop...|http://www.shop.c...|     Jessica Jones|  Ujjain|
|purchase|2022-11-12|2022-11-12 07:03:...|           UPI|Session_clickShop...|http://www.shop.c...|      Matt Murdock|  Ujjain|
|    view|2022-09-07|2022-09-07 10:30:...|            NA|Session_clickShop...|http://www.shop.c...|     Claire Temple|  Ujjain|
|    view|2022-09-10|2022-09-10 09:21:...|            NA|Session_clickShop...|http://www.shop.c...|      Foggy Nelson|  Ujjain|
|    view|2022-06-26|2022-06-26 01:44:...|            NA|Session_clickShop...|http://www.shop.c...|        Karen Page|  Ujjain|
|purchase|2022-11-06|2022-11-06 06:51:...|           COD|Session_clickShop...|http://www.shop.c...|           Lucifer|  Ujjain|
|    view|2022-10-26|2022-10-26 02:19:...|            NA|Session_clickShop...|http://www.shop.c...|     Ryan Reynolds|  Ujjain|
|purchase|2022-07-12|2022-07-12 07:11:...|   Credit Card|Session_clickShop...|http://www.shop.c...|      Peter Parker|  Ujjain|
|    view|2022-10-06|2022-10-06 12:29:...|            NA|Session_clickShop...|http://www.shop.c...|        Tony Stark|  Ujjain|
|purchase|2022-06-27|2022-06-27 11:37:...|        PayPal|Session_clickShop...|http://www.shop.c...|     Ryan Reynolds|  Ujjain|
|purchase|2022-07-26|2022-07-26 05:51:...|    Debit Card|Session_clickShop...|http://www.shop.c...|     Ryan Reynolds|  Ujjain|
|purchase|2022-08-03|2022-08-03 12:01:...|    NetBanking|Session_clickShop...|http://www.shop.c...|     Jessica Jones|  Ujjain|
|purchase|2022-09-15|2022-09-15 05:56:...|        PayPal|Session_clickShop...|http://www.shop.c...|      Clint Barton|  Ujjain|
|purchase|2022-07-06|2022-07-06 01:46:...|   Credit Card|Session_clickShop...|http://www.shop.c...|        Tony Stark|  Ujjain|
|    view|2022-06-16|2022-06-16 09:16:...|            NA|Session_clickShop...|http://www.shop.c...|Scarlett Johansson|  Ujjain|
|purchase|2022-11-06|2022-11-06 11:51:...|   Credit Card|Session_clickShop...|http://www.shop.c...|     Claire Temple|  Ujjain|
|purchase|2022-10-20|2022-10-20 11:46:...|    Debit Card|Session_clickShop...|http://www.shop.c...|       Chris Evans|  Ujjain|
|purchase|2022-10-23|2022-10-23 10:55:...|        PayPal|Session_clickShop...|http://www.shop.c...|           Elektra|  Ujjain|
+--------+----------+--------------------+--------------+--------------------+--------------------+------------------+--------+
only showing top 20 rows

root
 |-- action: string (nullable = true)
 |-- logdate: string (nullable = true)
 |-- logtime: string (nullable = true)
 |-- payment_method: string (nullable = true)
 |-- sessionid: string (nullable = true)
 |-- url: string (nullable = true)
 |-- userid: string (nullable = true)
 |-- location: string (nullable = true)

[+] Creating view of actions for table join query...
[+] ShoppingCartAnalysis_item data stored into Hive table successfully...!!!


[+] Starting Zeppelin server
Please specify HADOOP_CONF_DIR if USE_HADOOP is true
Zeppelin start [60G[[1;32m  OK  [0;39m]
[+] Opening Visualization notebook


